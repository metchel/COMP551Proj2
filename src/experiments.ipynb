{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) load in training data from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pos_examples = [open('../data/train/pos/' + f).read() for f in os.listdir('../data/train/pos')]\n",
    "neg_examples = [open('../data/train/neg/' + f).read() for f in os.listdir('../data/train/neg')]\n",
    "\n",
    "X = pos_examples + neg_examples\n",
    "y = [1 if i < len(pos_examples) else 0 for i in range(len(pos_examples) + len(neg_examples))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) perform the following steps of preprocessing:\n",
    "    (a) remove punctuation\n",
    "    (b) remove stop words\n",
    "    (c) stem\n",
    "    (d) identify simple negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br>Hi this?? ;is</br> not. Hello There DUDe the!! coolest thing I've NEVER ever seen\n",
      "exclams\n",
      "2.0\n",
      "nan\n",
      "lengths\n",
      "14.0\n",
      "nan\n",
      "uppers\n",
      "1.0\n",
      "nan\n",
      "Hi    not_ hello there dude   coolest thing I ve not_ever seen\n",
      "exclams\n",
      "0.0\n",
      "0.0\n",
      "lengths\n",
      "135.8932\n",
      "132.46808\n",
      "uppers\n",
      "0.71536\n",
      "0.7624\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "        \n",
    "def clean(X):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    X_clean = []\n",
    "    negative = ['not', 'hardly', 'isnt', 'no', 'n\\'t', 'never', 'can\\'t', 'won\\'t', 'don\\'t', 'havn\\'t', 'didn\\'t', 'hasn\\'t', 'wouldn\\'t', 'couldn\\'t', 'shouldn\\'t']\n",
    "    exclams = []\n",
    "    lengths = []\n",
    "    uppercases = []\n",
    "    for x_i in X:\n",
    "        exclam = x_i.count('!')\n",
    "        length = len(x_i.split())\n",
    "        exclams.append(exclam)\n",
    "        lengths.append(length)\n",
    "        x_i = re.sub(r'<.*?>', '', x_i)\n",
    "        tokens = word_tokenize(x_i)\n",
    "        uppers = len([w for w in tokens if w.isupper() and not w is 'I'])\n",
    "        uppercases.append(uppers)\n",
    "        x_i = x_i.lower()\n",
    "        clean = [stemmer.stem(w) for w in tokens if not w in stop_words or w in negative]\n",
    "        for c in string.punctuation:\n",
    "            clean = [w.replace(c, '') for w in clean]\n",
    "        negated = ['not_' + clean[i] if clean[i-1] in negative else clean[i] for i in range(len(clean))]\n",
    "        remove_negative = [w for w in negated if w not in negative]\n",
    "        clean_2 = \" \".join(remove_negative)\n",
    "        X_clean.append(clean_2)\n",
    "    print('exclams')\n",
    "    print(np.mean(exclams[:12500]))\n",
    "    print(np.mean(exclams[12500:]))\n",
    "    print('lengths')\n",
    "    print(np.mean(lengths[:12500]))\n",
    "    print(np.mean(lengths[12500:]))\n",
    "    print('uppers')\n",
    "    print(np.mean(uppercases[:12500]))\n",
    "    print(np.mean(uppercases[12500:]))\n",
    "    return X_clean\n",
    "\n",
    "def test_clean(test_text_list):\n",
    "    print(test_text_list[0])\n",
    "    test_text_list = clean(test_text_list)\n",
    "    print(test_text_list[0])\n",
    "    \n",
    "test_clean(['<br>Hi this?? ;is</br> not. Hello There DUDe the!! coolest thing I\\'ve NEVER ever seen'])\n",
    "X = clean(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) split the dataset into 80% train, 20% validate\n",
    "#### (4) TFIDF vectorization \n",
    "        - played around with parameters, using unigrams/bigrams and ~75k features is best\n",
    "#### (5) Grid search for Logistic regression parameter tuning\n",
    "        - varied C (inverse regulatization) and penalty (l1 or l2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "def mutual_info(X, y, words):\n",
    "        if isinstance(X, list):\n",
    "            X = np.array(X)\n",
    "        n, m = X.shape\n",
    "        print(len(words))\n",
    "        class_counts = {0: 0, 1: 0}\n",
    "        feature_counts = {0: np.zeros(m), 1: np.zeros(m)}\n",
    "        sqr_diff = []\n",
    "        class_probabilities = {}\n",
    "        feature_probabilities = {}\n",
    "\n",
    "        for y_i in y:\n",
    "            class_counts[y_i] += 1\n",
    "\n",
    "        sparse_matrix = sparse.csr_matrix(X).nonzero()\n",
    "        (row, col) = sparse_matrix\n",
    "        for i in range(len(row)):\n",
    "            c = y[row[i]]\n",
    "            feature_counts[c][col[i]] += 1\n",
    "\n",
    "        class_probabilities = {0: class_counts[0]/float(n), 1: class_counts[1]/float(n)}\n",
    "        feature_probabilities = {\n",
    "            0: [(feature_count + 1)/float(class_counts[0] + 2) for feature_count in feature_counts[0]],\n",
    "            1: [(feature_count + 1)/float(class_counts[1] + 2) for feature_count in feature_counts[1]]\n",
    "        }\n",
    "        info = []\n",
    "        for i in range(m):\n",
    "            prob_word_0 = feature_probabilities[0][i]\n",
    "            prob_word_1 = feature_probabilities[1][i]\n",
    "            prob_word = prob_word_0 + prob_word_1\n",
    "            \n",
    "            prob_0_1 = prob_word_0*math.log(((prob_word_0)/(prob_word*class_probabilities[0])))\n",
    "            prob_0_0 = (1 - prob_word_0)*math.log((1 - prob_word_0)/(prob_word*class_probabilities[0]))\n",
    "            \n",
    "            prob_1_1 = prob_word_1*math.log((prob_word_1)/(prob_word*class_probabilities[1]))\n",
    "            prob_1_0 = (1 - prob_word_1)*math.log((1 - prob_word_1))/(prob_word*class_probabilities[1])\n",
    "            \n",
    "            info.append((words[i], sum([prob_0_1, prob_0_0, prob_1_1, prob_1_0])))\n",
    "        return info\n",
    "    \n",
    "def count_questions(X):\n",
    "    return [x_i.count('?')/float(len(x_i.split())) for x_i in X]\n",
    "\n",
    "questions_train, questions_validate = count_questions(train_X), count_questions(validate_X)\n",
    "\n",
    "def get_vocab(X_t, y_t):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    negatives = ['not', 'hardly', 'isnt', 'no', 'n\\'t', 'never', 'can\\'t', 'won\\'t', 'don\\'t', 'havn\\'t', 'didn\\'t', 'hasn\\'t', 'wouldn\\'t', 'couldn\\'t', 'shouldn\\'t']\n",
    "    vectorizer = CountVectorizer(binary=False, analyzer='word', ngram_range=(1, 1), max_features=150000)\n",
    "    vectorizer_2 = CountVectorizer(binary=False, analyzer='word', ngram_range=(2, 2), max_features=50000)\n",
    "    \n",
    "    single_counts = vectorizer.fit_transform(X_t)\n",
    "    double_counts = vectorizer_2.fit_transform(X_t)\n",
    "    single_vocab = vectorizer.get_feature_names()\n",
    "    double_vocab = vectorizer_2.get_feature_names()\n",
    "    \n",
    "    info_1 = mutual_info(single_counts, y_t, single_vocab)\n",
    "    info_2 = mutual_info(double_counts, y_t, double_vocab)\n",
    "    \n",
    "    all_info = info_1 + info_2\n",
    "    all_info = sorted(all_info, key = lambda x: x[1])\n",
    "    all_info = [x[0] for x in all_info]\n",
    "    all_info = [w for w in all_info if w not in stop_words and w not in negatives]\n",
    "    return all_info\n",
    "    \n",
    "#VOCAB = get_vocab(train_X, train_y)\n",
    "#print(VOCAB[:100])\n",
    "vect_count = CountVectorizer(binary=False, analyzer='word', ngram_range=(1, 2), max_features=250000)\n",
    "\n",
    "counts = vect_count.fit_transform(train_X)\n",
    "word_features = vect_count.get_feature_names()\n",
    "print(len(word_features))\n",
    "\n",
    "vect_tfidf = TfidfTransformer()\n",
    "\n",
    "#print(vect_tfidf.get_feature_names())\n",
    "#nb = BernoulliNB()\n",
    "#nb.fit(train_features, train_y)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "grid = {'C': [1, 5, 10, 15, 20, 25, 30]}\n",
    "\n",
    "lr_cv = GridSearchCV(lr, grid, cv=10, error_score='raise')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Include both training and validation data in the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.8998222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      1209\n",
      "           1       0.89      0.91      0.90      1291\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2500\n",
      "   macro avg       0.89      0.89      0.89      2500\n",
      "weighted avg       0.89      0.89      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vect_tfidf = TfidfTransformer()\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "grid = {'C': [1, 5, 10]}\n",
    "\n",
    "lr_cv = GridSearchCV(lr, grid, cv=10, error_score='raise')\n",
    "\n",
    "all_features = hstack(((np.array(questions_train)[:,None], vect_tfidf.fit_transform(counts))))\n",
    "validate_features = hstack((np.array(questions_validate)[:,None], vect_tfidf.transform(vect_count.transform(validate_X))))\n",
    "#all_features = vect_tfidf.fit_transform(counts)\n",
    "#validate_features = vect_tfidf.transform(vect_count.transform(validate_X))\n",
    "lr_cv.fit(all_features, train_y)\n",
    "print(lr_cv.best_params_)\n",
    "print(lr_cv.best_score_)\n",
    "\n",
    "preds = lr_cv.best_estimator_.predict(validate_features)\n",
    "print(classification_report(validate_y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.2965765    6.3056383  -12.041158    -4.344803     4.087066\n",
      "   2.762565     1.173731     6.3358917   -0.56823426   4.7318172 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "all_y = train_y + validate_y\n",
    "documents = [TaggedDocument(doc.split(), [i, all_y[i]]) for i, doc in enumerate(train_X + validate_X)]\n",
    "model = Doc2Vec(documents, vector_size=10, window=2, min_count=1, workers=1)\n",
    "print(model.docvecs[0])\n",
    "\n",
    "feats = [list(model.docvecs[i]) for i in range(len(model.docvecs))]\n",
    "\n",
    "X_training = feats[:len(train_X)]\n",
    "X_validating = feats[len(train_X):]\n",
    "#X_training_sparse = hstack((all_features, X_training))\n",
    "#X_validating_sparse = hstack((validate_features, X_validating))\n",
    "                         \n",
    "print(X_training)\n",
    "print(X_validating)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_training, train_y)\n",
    "pred = lr.predict(X_validating)\n",
    "print(classification_report(validate_y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 0.9676274061203003), ('probabl', 0.9330042004585266), ('hammerheadhuman', 0.9208669066429138), ('noteven', 0.9189362525939941), ('mayb', 0.9169903993606567), ('It', 0.912951648235321), ('bullshit', 0.912523090839386), ('yawninduc', 0.911584734916687), ('duplic', 0.9085726737976074), ('sequel', 0.9084675312042236)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.wv.most_similar('movi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7) Calculate test results and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclams\n",
      "1.0008\n",
      "0.96752\n",
      "lengths\n",
      "226.79408\n",
      "230.25928\n",
      "uppers\n",
      "2.02408\n",
      "2.07096\n",
      "think could get better worst assumpt I ever made  drivvl not_describ movi appropri enough  not_plot thin  I get emot act pet fish  It shame see pete postlethwait  I respect actor tri best littl work  I think cardboard cut stephen baldwin would done better job  fact animateavoid cost  thi could realli hazard health \n",
      "[('movi', 49543), ('film', 45922), ('nt', 32823), ('one', 25420), ('like', 21506), ('time', 14796), ('make', 13772), ('charact', 13769), ('good', 13671), ('see', 13547), ('watch', 13367), ('get', 13264), ('thi', 13119), ('would', 13042), ('stori', 11595), ('even', 11373), ('realli', 10644), ('scene', 10531), ('show', 9748), ('well', 9456), ('look', 9441), ('could', 9102), ('end', 8953), ('love', 8899), ('great', 8849), ('much', 8829), ('peopl', 8826), ('also', 8634), ('think', 8456), ('play', 8417), ('bad', 8400), ('go', 8352), ('act', 8295), ('first', 8150), ('thing', 8128), ('way', 7852), ('made', 7282), ('say', 7167), ('know', 7151), ('seem', 6722), ('mani', 6616), ('actor', 6437), ('two', 6364), ('plot', 6364), ('work', 6338), ('want', 6335), ('come', 6253), ('take', 6246), ('tri', 6023), ('seen', 5964), ('best', 5939), ('littl', 5914), ('year', 5888), ('ever', 5792), ('life', 5788), ('man', 5486), ('give', 5474), ('better', 5441), ('find', 5191), ('still', 5174), ('perform', 5074), ('use', 4910), ('part', 4907), ('someth', 4896), ('lot', 4854), ('feel', 4848), ('actual', 4802), ('guy', 4772), ('back', 4566), ('interest', 4472), ('director', 4433), ('real', 4184), ('music', 4168), ('anoth', 4075), ('though', 4058), ('cast', 4050), ('live', 4038), ('noth', 4011), ('enjoy', 3994), ('funni', 3990), ('role', 3953), ('start', 3918), ('everi', 3917), ('old', 3800), ('new', 3778), ('us', 3725), ('girl', 3686), ('set', 3640), ('turn', 3637), ('star', 3617), ('thought', 3597), ('point', 3594), ('believ', 3587), ('kill', 3587), ('world', 3582), ('day', 3579), ('fact', 3548), ('pretti', 3531), ('effect', 3522), ('ca', 3512)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 145869 features per sample; expecting 145870",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-a3dcd64c425e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 145869 features per sample; expecting 145870"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "test = {}\n",
    "for n in range(25000):\n",
    "    filename = '../data/test/{}.txt'.format(n)\n",
    "    test[n] = open(filename, 'r').read()\n",
    "    \n",
    "test_X = list(test.values())\n",
    "test_X = clean(test_X)\n",
    "print(test_X[0])\n",
    "\n",
    "test_counts = vect_count.transform(test_X)\n",
    "sum_words = test_counts.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vect_count.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "print(words_freq[:100])\n",
    "\n",
    "test_features = vect_tfidf.transform(test_counts)\n",
    "predictions = lr_cv.best_estimator_.predict(test_features)\n",
    "\n",
    "with open('results.csv', 'w') as results:\n",
    "    writer = csv.writer(results, delimiter=',')\n",
    "    writer.writerow(['Id', 'Category'])\n",
    "    for i in range(25000):\n",
    "        writer.writerow([i, predictions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
